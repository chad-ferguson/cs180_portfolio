<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Project 3 — (Auto)-Stitching Photo Mosaics</title>
  <link rel="stylesheet" href="project.css" />
  <meta name="description" content="CS180 Project 3A" />
</head>
<body>
  <header class="site-header container">
    <nav class="breadcrumb">
      <a href="../../index.html">← Back to Portfolio</a>
    </nav>

    <h1>Project 3: (Auto)-Stitching Photo Mosaics</h1>
    <div class="rule"></div>

    <div class="quick-links" role="navigation" aria-label="Jump to section">
      <div class="link-row">
        <a class="btn" href="#a1">A.1 Shoot</a>
        <a class="btn" href="#a2">A.2 Homographies</a>
        <a class="btn" href="#a3">A.3 Rectify</a>
        <a class="btn" href="#a4">A.4 Mosaic</a>
      </div>

      <div class="link-row">
        <a class="btn" href="#b1">B.1 Corner Detection</a>
        <a class="btn" href="#b2">B.2 Feature Extraction</a>
        <a class="btn" href="#b3">B.3 Feature Matching</a>
        <a class="btn" href="#b4">B.4 RANSAC</a>
      </div>
    </div>
  </header>

  <main class="container article">

    <!-- A.1 -->
    <section id="a1" class="section">
      <h2>A.1 — Shoot the Pictures</h2>
      <p class="lede">
        Displayed below are 3 of the many image pairs I took for this project. Each pair has a fixed center of projection so that the transforms between them are projective, with some overlap in the middle to find correspondences.
      </p>
      
      <h3>Park Bench</h3>
      <div class="figure duo tight">
        <figure class="card"><div class="media-frame"><img src="media/A_1/bench_left.png"  alt="bench_left"></div></figure>
        <figure class="card"><div class="media-frame"><img src="media/A_1/bench_right.png" alt="bench_right"></div></figure>
      </div>
      
      <h3>Trucks</h3>
      <div class="figure duo tight">
        <figure class="card"><div class="media-frame"><img src="media/A_1/trucks_left.png"  alt="trucks_left"></div></figure>
        <figure class="card"><div class="media-frame"><img src="media/A_1/trucks_right.png" alt="trucks_right"></div></figure>
      </div>

      <h3>Street View</h3>
      <div class="figure duo tight">
        <figure class="card"><div class="media-frame"><img src="media/A_1/street_left.png"  alt="street_left"></div></figure>
        <figure class="card"><div class="media-frame"><img src="media/A_1/street_right.png" alt="street_right"></div></figure>
      </div>

    </section>

    <!-- A.2 -->
    <section id="a2" class="section">
      <h2>A.2 — Recover Homographies</h2>
      <p class="lede">
        To recover homographies, we first need correspondences between each image. 
        For this part, I manually recorded the pixel coordinates in each image using 
        <a href="https://pixspy.com" target="_blank" rel="noopener noreferrer">pixspy.com</a>. These points are overlayed on the image and displayed below.
      </p>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_2/benches.png" alt="Correspondences: benches">
        </div>
      </figure>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_2/street.png" alt="Correspondences: street">
        </div>
      </figure>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_2/trucks.png" alt="Correspondences: trucks">
        </div>
      </figure>

      <h3>Computing H</h3>
        <p class="muted">
          To compute H, as seen in discussion #5, we can solve for the system of equations by taking a single point and solving for u and v in terms of x, y, and the elements of H. Each point gives us two equations, so we need at least 4 correspondence points. Below is the complete system of equations for 4 involved correspondences.
        </p>
        <figure class="equation card">
          <a href="media/A_2/eqs.png" target="_blank" rel="noopener">
            <div class="media-frame">
              <img src="media/A_2/eqs.png" alt="">
            </div>
          </a>
        </figure>
        <p class="muted">
          Note, that the h vector make up the components of the H matrix, with the bottom right always being 1, see below.
        </p>
        <figure class="equation small card">
          <a href="media/A_2/H.png" target="_blank" rel="noopener">
            <div class="media-frame">
              <img src="media/A_2/H.png" alt="">
            </div>
          </a>
        </figure>
        <p class="muted">
          Also note that this system of equations is overdetermined for any more than 4 points (A would be taller to fit more points in). In this case we need to use least squares to solve for the elements of H, finding the minimum error for h to satisfy Ah=b.
        </p>
        <p class="muted">
          Below are the results on the bench image pair's correspondence points. A similar process is run for each set of images.
        </p>
        <figure class="equation card">
          <a href="media/A_2/benches_eq.png" target="_blank" rel="noopener">
            <div class="media-frame">
              <img src="media/A_2/benches_eq.png" alt="">
            </div>
          </a>
        </figure>
      </div>
    </section>

    <!-- A.3 -->
    <section id="a3" class="section">
      <h2>A.3 — Warp the Images</h2>
      <p class="lede">
        In this part, we implement inverse warping with both nearest neighbor and bilinear interpolation. Using the homography matrix function from before, we can then rectify images by finding the projective transformation of the image corners to a true rectangle. This process is displayed below for two posters on my wall.
      </p>

      <figure class="card pan-x">
        <div class="media-frame no-pad">
          <img class="wide" src="media/A_3/poster1_rectified.png" alt="Rectification case 1">
        </div>
      </figure>

      <figure class="card pan-x">
        <div class="media-frame no-pad">
          <img class="wide" src="media/A_3/poster2_rectified.png" alt="Rectification case 2">
        </div>
      </figure>

      <h3>Comparison</h3>
      <p class="muted">
        Although both methods are very similar, we can see a difference if we zoom in. Below, are zoomed in images of the right border of poster 1 after rectification. We can see that the border for NN is more jagged or stepped, while the bilinear implementation is much smoother. There is a small speed tradeoff since the NN interpolation does run a bit faster than the bilinear interpolation.
      </p>
      <div class="figure duo tight zoom-pair">
        <figure class="card">
          <div class="media-frame">
            <img src="media/A_3/nn_zoom.png" alt="">
          </div>
          <figcaption class="muted">Nearest-Neighbor Interpolated Edge</figcaption>
        </figure>

        <figure class="card">
          <div class="media-frame">
            <img src="media/A_3/bi_zoom.png" alt="">
          </div>
          <figcaption class="muted">Bilinear Interpolated Edge</figcaption>
        </figure>
      </div>
      </div>
    </section>

    <!-- A.4 -->
    <section id="a4" class="section">
      <h2>A.4 — Blend the Images into a Mosaic</h2>
      <p class="lede">
        In this part, we use the homographies for the image pairs that we calculated earlier to blend the images into a mosaic, as seen below. To do this, I first compute the output image size necessary to fit both images in full. Then, the right image is simply translated to its spot on the new canvas. Then, the left image is inverse warped (like in the last part) onto the output canvas with bilinear interpolation, using the translation matrix and the homography calculated between the left and right images. The outputs has some seams, which are handled with blending described below the outputs.
      </p>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_4/bench_mosaic.png"  alt="Bench mosaic">
        </div>
      </figure>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_4/street_mosaic.png" alt="Street mosaic">
        </div>
      </figure>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/A_4/trucks_mosaic.png" alt="Trucks mosaic">
        </div>
      </figure>

        <h3>Blending Details</h3>
        <p class="muted">
          After the images are in the correct place, there is typically a small seam between the overlap of the images, or imperfect sections off detail in the overlap (ghosting). To solve this, I decided to use the distance transform to have an alpha mask fall off linearly until it hits the edge's black pixel. I then used the function from my project 2 code to build laplacian stacks for the images and a guassian stack for the mask to apply a 2 level pyramid blend to the output. We can then blend at both levels of the pyramid and sum the levels to get the output image, a blending process that is fairly similar to the project 2's multiresolution blending section!
        </p>
    </section>

    <!-- B.1 -->
    <section id="b1" class="section">
      <h2>B.1 — Harris Corner Detection</h2>
      <p class="lede">
        In this part, we detect Harris corners in the images, and then use Adaptive Non-Maximal Suppression (ANMS) to filter to the best local corners in each area of the image. Below is all of the Harris Corners and then the ANMS corners for both the left and right bench image which we previously manually created a mosaic of. The image is full of Harris corners, with only areas that are a patch of the same color (like the man's white shirt) not being detected.
      </p>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/B_1/bench_harris_all.png" alt="All Harris Corners">
        </div>
      </figure>

      <figure class="card mega">
        <div class="media-frame">
          <img src="media/B_1/bench_harris_anms.png" alt="ANMS Corners">
        </div>
      </figure>
    </section>

    <!-- B.2 -->
    <section id="b2" class="section">
      <h2>B.2 — Feature Descriptor Extraction</h2>
      <p class="lede">
        In this part, we first blur and grayscale the image and then extract the 40x40 pixel window that surrounds each ANMS corner. The goal here is to be able to uniquely identify each detected corner to later match the descriptors between the two images. The outputs below for the left and right images show that some of the descriptors are not unique and cannot be used reliably. For example, the gradient looking descriptor for corners in the sky is basically identical for many of the detected corners and would cause trouble if we decided to calculate the homography on these corners. On the other hand, feature descriptors like points #4 in each image are great corners to compute the homography on.
      </p>

      <div class="figure duo tight">
        <figure class="card">
          <div class="media-frame"><img src="media/B_2/left_patch_points.png" alt="Left patch points"></div>
          <figcaption class="muted">Left Image Corners</figcaption>
        </figure>
        <figure class="card">
          <div class="media-frame"><img src="media/B_2/left_patches.png" alt="Left patches"></div>
          <figcaption class="muted">Left Image Corresponding Patches</figcaption>
        </figure>
      </div>

      <div class="figure duo tight">
        <figure class="card">
          <div class="media-frame"><img src="media/B_2/right_patch_points.png" alt="Right patch points"></div>
          <figcaption class="muted">Right Image Corners</figcaption>
        </figure>
        <figure class="card">
          <div class="media-frame"><img src="media/B_2/right_patches.png" alt="Right patches"></div>
          <figcaption class="muted">Right Image Corresponding Patches</figcaption>
        </figure>
      </div>
    </section>

    <!-- B.3 -->
    <section id="b3" class="section">
      <h2>B.3 — Feature Matching</h2>
      <p class="lede">
        In this part, we take the detected corners and match their feature descriptors between the two images to calculate correspondences. To find good matches, we cannot simply take descriptors that look the same though. Remember that two descriptors in the sky may be identical but actually be on opposite sides of the scene. A good match should be distinct. We calculate the best match and then the second best match for a point, and only accept the best match if the ratio between the top two matches meets a certain threshold. I defined my threshold as 0.67, but anything in this range should realistically work well. I displayed the results for the top 25 matches below. The results are still not perfect, but most of the points are correctly matched.
      </p>

      <figure class="card pan-x">
        <div class="media-frame no-pad">
          <img class="wide" src="media/B_3/bench_matches_top.png" alt="Matched features">
        </div>
      </figure>
    </section>

    <!-- B.4 -->
    <section id="b4" class="section">
      <h2>B.4 — RANSAC for Robust Homography</h2>
      <p class="lede">
        Finally, we use the detected and matched features to compute homographies and create mosaics without having to manually define correspondences like in part A. To do this we use an algorithm called Random Sample Consensus (RANSAC). This iterative algorithm continuously samples 4 random matched corner pairs, computes the homography, applies that homography to all the points, and then looks at the amount of inliers, or points that are satisfied by the calculated homography. The best 4 points should result in the highest amount of inliers. After iterating a bunch of times, we then finally compute the final homography by running least squares on all of the inliers. We can see that this does give slightly better results than in part A.4 in areas like the grass or asphalt. However, more importantly, it is automated! I also created two additional mosaics in this part that I had trouble with manually doing in part A.
      </p>

      <figure class="card mega">
        <div class="media-frame"><img src="media/B_4/bench_auto_mosaic.png" alt="Bench Auto Mosaic"></div>
      </figure>

      <figure class="card mega">
        <div class="media-frame"><img src="media/B_4/street_auto_mosaic.png" alt="Street Auto Mosaic"></div>
      </figure>

      <figure class="card mega">
        <div class="media-frame"><img src="media/B_4/trucks_auto_mosaic.png" alt="Trucks Auto Mosaic"></div>
      </figure>

      <figure class="card mega">
        <div class="media-frame"><img src="media/B_4/street2_auto_mosaic.png" alt="Street Auto Mosaic 2"></div>
      </figure>

      <figure class="card mega">
        <div class="media-frame"><img src="media/B_4/street3_auto_mosaic.png" alt="Street Auto Mosaic 3"></div>
      </figure>
    </section>

  </main>
</body>
</html>
